
# ğŸ¯ Financial-Intent-Understanding-with-LLMs

<div align="left">

Fine-tuning LLMs using LlamaFactory | Evaluating Open-source Financial Datasetsã€Financial Intent Understandingã€‘

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/release/python-380/)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Framework: LlamaFactory](https://img.shields.io/badge/Framework-LlamaFactory-green.svg)](https://github.com/hiyouga/LLaMA-Factory)

<p align="center">
  <a href="#-project-introduction">Project Introduction</a> â€¢
  <a href="#-quick-start">Quick Start</a> â€¢
  <a href="#-dataset-content">Dataset Content</a> â€¢
  <a href="#-how-to-use">How to Use</a> â€¢
  <a href="#-experimental-results">Experimental Results</a> â€¢
  <a href="#-faq">FAQ</a>
  <a href="#-project-structure">Project Structure</a>
  <a href="#-related-resources">Related Resources</a>
</p>

[ç®€ä½“ä¸­æ–‡](README.md) | English

</div>

## ğŸ“– Project Introduction

This project demonstrates how to fine-tune large language models using LlamaFactory for specific financial domain tasks. We selected the financial intent understanding task from the open-source financial evaluation dataset [OpenFinData](https://github.com/open-compass/OpenFinData) as an example to explore the performance of mainstream open-source large models.

### ğŸ¯ Project Goals
- Provide a complete LLM fine-tuning practice case
- Evaluate mainstream open-source models' capabilities in financial intent understanding
- Explore the performance improvement through LoRA fine-tuning
- Provide reference for LLM applications in the financial domain

### ğŸ” Core Content

1. **Dataset Preparation**
   - Evaluation Dataset: Using [OpenFinData](https://github.com/open-compass/OpenFinData) financial intent understanding subset
   - Training Dataset: 500 training samples and 160 validation samples generated by Claude3.5-sonnet. Following Alpaca format, uploaded to [HuggingFace](https://huggingface.co/datasets/klaylouis1932/OpenFinData-Intent-Understanding-Intruct)

2. **Model Selection**
   - ChatGLM3-6B: Open-source Chinese dialogue model by Zhipu AI
   - Qwen2.5-7B-Instruct: General-purpose model by Alibaba Cloud
   - Baichuan2-7B-Chat: Dialogue model by Baichuan Intelligence
   - Llama-3-8B-Instruct: Open-source model by Meta

## ğŸš€ Quick Start

```bash
# 1. Clone the project
git clone https://github.com/yourusername/Financial-Intent-Understanding-with-LLMs.git
cd Financial-Intent-Understanding-with-LLMs

# 2. Install LlamaFactory
git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -e ".[torch,metrics]"
cd ..

# 3. Prepare dataset
# Add to data/dataset_info.json, example:
{
  "intent_understanding": {
    "hf_hub_url": "klaylouis1932/OpenFinData-Intent-Understanding-Intruct"
  }
}

# 4. Start training (using Qwen as example)
!llama_factory train config/qwen25/qwen25_7b_lora_sft.yaml

# 5. Export model (using Qwen as example)
!llama_factory export config/qwen25/qwen25_7b_lora_sft_export.yaml

# 6. Model inference
!llama_factory inference config/qwen25/qwen25_7b_lora_sft_inference.yaml
```

## ğŸ“Š Dataset Content

<details>
<summary>Click to expand dataset details</summary>

### Original Data Format
    {
        "id": "0",
        "question": "You are an intent and emotion assistant. Please analyze which of the following intents [Market Inquiry, Industry Sector Inquiry, Individual Stock Inquiry, Fund Inquiry, Customer Service Inquiry] does this question belong to? Please provide the correct option.\nQuestion: How about commercial banks?",
        "A": "Industry Sector Inquiry",
        "B": "Individual Stock Inquiry",
        "C": "Market Inquiry",
        "D": "Customer Service Inquiry",
        "E": "Fund Inquiry",
        "answer": "A"
    }
![Data Format 1](assets/dataset-1.png)

### Processed Data Format
`instruction`:
As an intent and emotion assistant, please analyze the intent type of the following question.

Question: How about commercial banks?

Please choose the most appropriate intent type from the following options:
A. Industry Sector Inquiry
B. Individual Stock Inquiry
C. Market Inquiry
D. Customer Service Inquiry
E. Fund Inquiry

Please only answer with the option letter (A, B, C, D, or E).

 `input`: ""
 
 `output`: A
![Data Format 2](assets/dataset-2.png)

</details>

## ğŸ“ˆ Experimental Results

### Model Performance Comparison

| Model | Base Accuracy | Fine-tuned Accuracy | Improvement |
|-------|--------------|---------------------|-------------|
| Qwen2.5-7B-Instruct | 85.33% | 88.00% | +2.67% |
| Baichuan2-7B-Chat | 70.67% | 88.00% | +17.33% |
| Llama-3-8B-Instruct | 74.67% | 86.67% | +12.00% |
| ChatGLM3-6B | 49.33% | 85.33% | +36.00% |

### Key Findings
- All models showed significant improvement after LoRA fine-tuning
- Qwen2.5-7B-Instruct showed best baseline performance, demonstrating excellent zero-shot capability
- ChatGLM3-6B showed the most significant improvement (+36%)
- After fine-tuning, all models' performance converged to above 85% accuracy
- Claude-3.5 Sonnet achieved 94.67% accuracy on the same task (without fine-tuning)

## ğŸ’» Hardware Requirements
- AWS EC2 ml.g5.4xlarge instance
- GPU: A10G (24GB VRAM)
- Training time: About 10 minutes (single GPU training 500-600 samples)

## â“ FAQ

<details>
<summary>1. How to handle out-of-memory issues?</summary>

- Reduce batch_size
- Increase gradient_accumulation_steps
- Use bf16 training
- Enable 8-bit quantization training
- Reduce cutoff_length
</details>

## ğŸ“š Project Structure
```
â”œâ”€â”€ config/                     # Configuration files
â”‚   â”œâ”€â”€ qwen25/                  # Qwen model configs
â”‚   â”œâ”€â”€ chatglm3/             # ChatGLM3 model configs
â”‚   â”œâ”€â”€ baichuan2/             # Baichuan model configs
â”‚   â””â”€â”€ llama3/               # Llama3 model configs
â”œâ”€â”€ data/                      # Dataset related
â”‚   â””â”€â”€ dataset_info.json     # Dataset configuration
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ notebooks/           # Notebooks for evaluation
â”‚   â””â”€â”€ results/             # Evaluation results
â”œâ”€â”€ README.md                 # Project documentation
â”œâ”€â”€ README_EN.md             # Project documentation (English)
```

## ğŸ“œ License

This project is licensed under the [Apache 2.0](LICENSE) License.

## ğŸ”— Related Resources

- [LlamaFactory](https://github.com/hiyouga/LLaMA-Factory)
- [OpenFinData Dataset](https://github.com/open-compass/OpenFinData)
- [Alpaca Data Format](https://github.com/tatsu-lab/stanford_alpaca)
